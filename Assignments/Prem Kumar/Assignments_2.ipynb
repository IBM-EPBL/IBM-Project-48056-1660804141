{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzViItRyQWnL"
      },
      "outputs": [],
      "source": [
        "#IMPORTING THE libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "#importing the dataset\n",
        "df=pd.read_csv(r\"E:\\assignment2\\Churn_Modelling.csv\")\n",
        "\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "\n",
        "#PERFORM VISUALIZATION\n",
        "#univariate analysis\n",
        "df.nunique()\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "#univariate analysis\n",
        "df.head()\n",
        "\n",
        "\n",
        "# In[27]:\n",
        "\n",
        "\n",
        "#Bi-variate analysis\n",
        "sns.FacetGrid(df,hue=\"IsActiveMember\",size=5)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# In[21]:\n",
        "\n",
        "\n",
        "#multi-variate analysis\n",
        "sns.pairplot(df, hue=\"IsActiveMember\", height=2)\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "#DESCRIPTION STATICS ON THE DATASET\n",
        "df.describe()\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "\n",
        "#HANDLE THE MISSING VALUES\n",
        "df.isnull().sum\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "#HANDLE THE MISSING VALUES\n",
        "df.isnull().sum().sum()\n",
        "\n",
        "\n",
        "# In[18]:\n",
        "\n",
        "\n",
        "#CHECKS FOR THE CATEGORICAL COLUMNS AND PERFORM ENCODING\n",
        "df.columns\n",
        "\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "\n",
        "#SPLIT THE DATA INTO DEPENDENT AND INDEPENDENT VARIABLES\n",
        "X = df.iloc[:, :2].values\n",
        "print(X)\n",
        "\n",
        "\n",
        "# In[36]:\n",
        "\n",
        "\n",
        "#Extracting the Dataset to Get the Dependent variable\n",
        "Y = df.iloc[:, :2].values\n",
        "print(Y)\n",
        "\n",
        "\n",
        "# In[42]:\n",
        "\n",
        "\n",
        "#SCALE THE INDEPENDENT VARIABLES\n",
        "# Initialise the Scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "# In[51]:\n",
        "\n",
        "\n",
        "#SPLIT THE DATA INTO TRAINING AND TESTING\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=2,random_state=0.2)\n",
        "\n",
        "\n",
        "# In[ ]:"
      ]
    }
  ]
}